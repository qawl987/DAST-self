{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from scipy import interpolate\n",
    "import scipy.io as sio\n",
    "from numpy import *\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 26)\n"
     ]
    }
   ],
   "source": [
    "#Import dataset\n",
    "RUL_F001 = np.loadtxt('./cmapss/RUL_FD001.txt')\n",
    "train_F001 = np.loadtxt('./cmapss/train_FD001.txt')\n",
    "test_F001 = np.loadtxt('./cmapss/test_FD001.txt')\n",
    "train_F001[:, 2:] = min_max_scaler.fit_transform(train_F001[:, 2:])\n",
    "test_F001[:, 2:] = min_max_scaler.transform(test_F001[:, 2:])\n",
    "train_01_nor = train_F001\n",
    "test_01_nor = test_F001\n",
    "print(train_01_nor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete worthless sensors\n",
    "train_01_nor = np.delete(train_01_nor, [5, 9, 10, 14, 20, 22, 23], axis=1) \n",
    "test_01_nor = np.delete(test_01_nor, [5, 9, 10, 14, 20, 22, 23], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of data process\n",
    "RUL_max = 125.0  \n",
    "window_Size = 40 \n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "trainY_bu = []\n",
    "testX = []\n",
    "testY = []\n",
    "testY_bu = []\n",
    "testInd = []\n",
    "testLen = []\n",
    "testX_all = []\n",
    "testY_all = []\n",
    "test_len = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出1~編號上限的引擎\n",
    "for i in range(1, int(np.max(train_01_nor[:, 0])) + 1):\n",
    "    # 用np.where取出一個tuple, array存的是所有編號為i的引擎數據\n",
    "    ind = np.where(train_01_nor[:, 0] == i)\n",
    "    # 取出tuple 中的ndarray\n",
    "    ind = ind[0]\n",
    "    data_temp = train_01_nor[ind, :]\n",
    "    for j in range(len(data_temp) - window_Size + 1): \n",
    "        trainX.append(data_temp[j:j + window_Size, 2:].tolist())\n",
    "        # j+windowsize 代表目前time total-current=RUL\n",
    "        train_RUL = len(data_temp) - window_Size - j\n",
    "        # 看目前的rul跟max差多少\n",
    "        train_bu = RUL_max - train_RUL\n",
    "        if train_RUL > RUL_max:\n",
    "            train_RUL = RUL_max\n",
    "            train_bu = 0.0\n",
    "        trainY.append(train_RUL)\n",
    "        trainY_bu.append(train_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set sliding time window processing\n",
    "for i in range(1, int(np.max(test_01_nor[:, 0])) + 1):\n",
    "    ind = np.where(test_01_nor[:, 0] == i)\n",
    "    ind = ind[0]\n",
    "    # 編號i的engine的total time\n",
    "    testLen.append(float(len(ind)))\n",
    "    data_temp = test_01_nor[ind, :]\n",
    "    # 編號i的最後time step\n",
    "    testY_bu.append(data_temp[-1, 1])\n",
    "    if len(data_temp) < window_Size:\n",
    "        \n",
    "        data_temp_a = []\n",
    "        # 特徵維度\n",
    "        for myi in range(data_temp.shape[1]):\n",
    "            # 根據 x數量 產生 0 ~ 40之間的x座標 \n",
    "            x1 = np.linspace(0, window_Size - 1, len(data_temp))\n",
    "            # 產生 0~40x座標\n",
    "            x_new = np.linspace(0, window_Size - 1, window_Size)\n",
    "            # 根據維度myi的點產生逼近函數\n",
    "            tck = interpolate.splrep(x1, data_temp[:, myi])\n",
    "            # 將0~40帶入tck產生的函數得y點\n",
    "            a = interpolate.splev(x_new, tck)\n",
    "            data_temp_a.append(a.tolist())\n",
    "        data_temp_a = np.array(data_temp_a)\n",
    "        data_temp = data_temp_a.T\n",
    "        data_temp = data_temp[:, 2:]\n",
    "    else:\n",
    "        # test 只要最後四十個預測還有多少RUL即可\n",
    "        data_temp = data_temp[-window_Size:, 2:]  \n",
    "    # for concate usage extand 0th dimension\n",
    "    data_temp = np.reshape(data_temp, (1, data_temp.shape[0], data_temp.shape[1])) \n",
    "    testX = data_temp if i == 1 else np.concatenate((testX, data_temp), axis=0)\n",
    "    if RUL_F001[i - 1] > RUL_max:\n",
    "        testY.append(RUL_max)\n",
    "        #testY_bu.append(0.0)\n",
    "    else:\n",
    "        testY.append(RUL_F001[i - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "testX = np.array(testX)\n",
    "trainY = np.array(trainY)/RUL_max \n",
    "trainY_bu = np.array(trainY_bu)/RUL_max\n",
    "testY = np.array(testY)/RUL_max\n",
    "testY_bu = np.array(testY_bu)/RUL_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16731, 40, 17)\n",
      "(16731,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16731, 40, 17)\n",
      "(100, 40, 17)\n",
      "(16731,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(trainY.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('F001_window_size_trainX.mat', {\"train1X\": trainX})\n",
    "sio.savemat('F001_window_size_trainY.mat', {\"train1Y\": trainY})\n",
    "sio.savemat('F001_window_size_testX.mat', {\"test1X\": testX})\n",
    "sio.savemat('F001_window_size_testY.mat', {\"test1Y\": testY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "mat = scipy.io.loadmat('F001_window_size_trainX.mat')\n",
    "struct_array = mat['']\n",
    "value = struct_array[0][0]['field_name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c30bcecd2be579928454f23a335de72e6ac700ea152f8294e8f6fe0cbdd0121a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
