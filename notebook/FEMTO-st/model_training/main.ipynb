{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kai/DAST/network')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import torch.utils.data.dataloader as Data\n",
    "import os\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from DAST_utils import *\n",
    "from DAST_Network import *\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class DASTModel():\n",
    "    def __init__(self, train_dataset_num, train_datasets: List[str], test_dataset: str, data_path: str, hyper_parameters: dict) -> None:\n",
    "        self.TRAIN_DATASET_NUM = train_dataset_num\n",
    "        self.TRAIN_DATASETS = train_datasets\n",
    "        self.TEST_DATASET = test_dataset\n",
    "        self.DATA_PATH = data_path\n",
    "        self.X_train_1 = None\n",
    "        self.Y_train_1 = None\n",
    "        self.X_train_2 = None\n",
    "        self.Y_train_2 = None\n",
    "        self.X_train_3 = None\n",
    "        self.Y_train_3 = None\n",
    "        self.X_test = None\n",
    "        self.Y_test = None\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "        self.HP = hyper_parameters\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.best_predict = []\n",
    "\n",
    "    @staticmethod\n",
    "    def RMSE(target, pred):\n",
    "        square_error = (target - pred) ** 2\n",
    "        mse =  (torch.sum(square_error)) / len(target)\n",
    "        rmse = mse ** 0.5\n",
    "        return rmse\n",
    "    \n",
    "    @staticmethod\n",
    "    def MAE(target, pred):\n",
    "        absolute_error = np.abs(target - pred)\n",
    "        return torch.sum(absolute_error) / len(target)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_list():\n",
    "        loss_list = []\n",
    "        train_loss_list = []\n",
    "        test_loss_list = []\n",
    "        best_mse_loss = 10000.0\n",
    "        return loss_list, train_loss_list, test_loss_list, best_mse_loss\n",
    "    \n",
    "    def _load_x_y(self, folder: str):\n",
    "        y_tmp = np.load(f'{self.DATA_PATH}/{folder}/{folder}_train_Y.npy')\n",
    "        return np.load(f'{self.DATA_PATH}/{folder}/{folder}_train_X.npy'), np.reshape(y_tmp, ((len(y_tmp), -1)))\n",
    "    \n",
    "    def _concate(self):\n",
    "        self.X_train = np.concatenate((self.X_train_1, self.X_train_2, self.X_train_3), axis=0)\n",
    "        self.Y_train = np.concatenate((self.Y_train_1, self.Y_train_2, self.Y_train_3), axis=0)\n",
    "\n",
    "    def _load_np(self, ):\n",
    "        for folder in self.TRAIN_DATASETS:\n",
    "            dataset_num = folder[-1]\n",
    "            if dataset_num == '1':\n",
    "                self.X_train_1, self.Y_train_1 = self._load_x_y(folder)\n",
    "            elif dataset_num == '2':\n",
    "                self.X_train_2, self.Y_train_2 = self._load_x_y(folder)\n",
    "            elif dataset_num == '4':\n",
    "                self.X_train_3, self.Y_train_3 = self._load_x_y(folder)\n",
    "        self.X_test = np.load(f'{self.DATA_PATH}/{self.TEST_DATASET}/{self.TEST_DATASET}_test_X.npy')\n",
    "        self.Y_test = np.load(f'{self.DATA_PATH}/{self.TEST_DATASET}/{self.TEST_DATASET}_test_Y.npy')\n",
    "        self.Y_test = np.reshape(self.Y_test, (len(self.Y_test), -1))\n",
    "        self._concate()\n",
    "            \n",
    "    def _tensorizing(self):\n",
    "        self.X_train = Variable(torch.Tensor(self.X_train).float())\n",
    "        self.Y_train = Variable(torch.Tensor(self.Y_train).float())\n",
    "        self.X_test = Variable(torch.Tensor(self.X_test).float())\n",
    "        self.Y_test = Variable(torch.Tensor(self.Y_test).float())\n",
    "        \n",
    "    def _get_dataloader(self):\n",
    "        train_dataset = TensorDataset(self.X_train, self.Y_train)\n",
    "        train_loader = Data.DataLoader(dataset=train_dataset, batch_size=self.HP['batch_size'], shuffle=False)\n",
    "        test_dataset = TensorDataset(self.X_test, self.Y_test)\n",
    "        test_loader = Data.DataLoader(dataset=test_dataset, batch_size=self.HP['batch_size'], shuffle=False)\n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def _get_model(self):\n",
    "        debug = False\n",
    "        model = DAST(self.HP['dim_val_s'], self.HP['dim_attn_s'], self.HP['dim_val_t'], self.HP['dim_attn_t'], self.HP['dim_val'], self.HP['dim_attn'], self.HP['time_step'], self.HP['input_size'], self.HP['dec_seq_len'], self.HP['output_sequence_length'], self.HP['n_decoder_layers'], self.HP['n_encoder_layers'], self.HP['n_heads'], debug)\n",
    "        model = model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.HP['lr'])\n",
    "        criterion = nn.MSELoss()\n",
    "        return model, optimizer, criterion\n",
    "    \n",
    "    def train(self, model, optimizer: torch.optim.Optimizer, criterion, train_loader: Data.DataLoader, loss_list: List[float], train_loss_list: List[float]):\n",
    "        for epoch in range(self.HP['epochs']):\n",
    "            #training\n",
    "            model.train()\n",
    "            loop = tqdm(train_loader, leave=True)\n",
    "            for _, (X, Y) in enumerate(loop):\n",
    "                batch_X = X.to(self.device)\n",
    "                batch_Y = Y.to(self.device)\n",
    "                out = model(batch_X)\n",
    "                loss = criterion(out, batch_Y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_list.append(loss.item())\n",
    "            loss_eopch = np.mean(np.array(loss_list))\n",
    "            train_loss_list.append(loss_eopch)\n",
    "            print('epoch = ',epoch,\n",
    "                    'train_loss = ',loss_eopch.item())\n",
    "\n",
    "    def eval(self, model, test_loader: Data.DataLoader, criterion, test_loss_list: List[float], best_mse_loss: float):\n",
    "        #testing\n",
    "        model.eval()\n",
    "        prediction_list = []\n",
    "        with torch.no_grad():\n",
    "            for _ ,(batch_x, _) in enumerate(test_loader):\n",
    "                batch_X = batch_x.to(self.device)\n",
    "                prediction = model(batch_X)\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "        out_batch_pre = torch.cat(prediction_list).detach().cpu()\n",
    "        rmse_loss = self.RMSE(self.Y_test, out_batch_pre, )\n",
    "        mae_loss = self.MAE(self.Y_test, out_batch_pre, )\n",
    "        test_loss = criterion(out_batch_pre, self.Y_test)\n",
    "        test_loss_list.append(test_loss)\n",
    "        if (test_loss.item() < best_mse_loss):\n",
    "            best_mse_loss = test_loss.item()\n",
    "            self.best_predict = np.reshape(out_batch_pre, (-1)).tolist()\n",
    "        print('rmse_loss = ', rmse_loss.item(),\n",
    "                'mae_loss = ', mae_loss.item(),\n",
    "                'mse_loss = ', test_loss.item())\n",
    "        \n",
    "    def main(self):\n",
    "        self._load_np()\n",
    "        self._tensorizing()\n",
    "        loss_list, train_loss_list, test_loss_list, best_mse_loss = self._get_list()\n",
    "        model, optimizer, criterion = self._get_model()\n",
    "        train_loader, test_loader = self._get_dataloader()\n",
    "        self.train(model, optimizer, criterion, train_loader, loss_list, train_loss_list)\n",
    "        self.eval(model, test_loader, criterion, test_loss_list, best_mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../../data/10FEMTO/processed_data/'\n",
    "FOLDER = 'Bearing1_1'\n",
    "TRAIN_DATASETS = ['Bearing1_1', 'Bearing1_2', 'Bearing1_4']\n",
    "TEST_DATASET = 'Bearing1_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE = 16\n",
    "EMBEDD = 20\n",
    "HYPER_PARAMETERS = {\n",
    "    'batch_size': 256,\n",
    "    'dim_val': FEATURE,\n",
    "    'dim_attn': EMBEDD,\n",
    "    'dim_val_t': FEATURE,\n",
    "    'dim_attn_t': EMBEDD,\n",
    "    'dim_val_s': FEATURE,\n",
    "    'dim_attn_s': EMBEDD,\n",
    "    'n_heads': 4,\n",
    "    'n_decoder_layers': 1,\n",
    "    'n_encoder_layers': 2,\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 3,\n",
    "    'time_step': 40,\n",
    "    'dec_seq_len': 4,\n",
    "    'output_sequence_length': 1,\n",
    "    'input_size': FEATURE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dast_model = DASTModel(train_dataset_num=3, train_datasets=TRAIN_DATASETS, test_dataset=TEST_DATASET, data_path=DATA_PATH, hyper_parameters=HYPER_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:00<00:00, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 40, 16]) torch.Size([256, 1])\n",
      "torch.Size([256, 1]) torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 train_loss =  0.2749629025674949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:00, 19.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 40, 16]) torch.Size([256, 1])\n",
      "torch.Size([256, 1]) torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1 train_loss =  0.16205271442195227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:00, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 40, 16]) torch.Size([256, 1])\n",
      "torch.Size([256, 1]) torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2 train_loss =  0.11962765271916093\n",
      "rmse_loss =  0.19501368701457977 mae_loss =  0.13987769186496735 mse_loss =  0.038030337542295456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dast_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dast_model._load_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.reshape(out_batch_pre, (-1))\n",
    "z = z.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y_test.detach().cpu().numpy()\n",
    "y = np.reshape(y, -1)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "\n",
    "# Plotting the line chart\n",
    "plt.plot(train_loss_list, label='Train loss', marker='o', markersize=1)\n",
    "plt.plot(test_loss_list, label='Test loss', marker='s', markersize=1)\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "\n",
    "# Plotting the line chart\n",
    "plt.plot(best_predict, label='Pred', marker='o', markersize=1)\n",
    "plt.plot(y, label='Y', marker='s', markersize=1)\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('RUL')\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "\n",
    "# Plotting the line chart\n",
    "plt.plot(z, label='Pred', marker='o', markersize=1)\n",
    "plt.plot(y, label='Y', marker='s', markersize=1)\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('RUL')\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Example data\n",
    "X_draw = X_train[:2763, 0, 4]\n",
    "# Plotting the line chart\n",
    "plt.plot(X_draw, label='Pred', marker='o', markersize=1)\n",
    "# plt.plot(Y_test, label='Y', marker='s', markersize=1)\n",
    "# Adding labels and title\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Bearing 1-1 Horizontal Vibration Signal')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "\n",
    "# Plotting the line chart\n",
    "plt.plot(X_train[0], label='Pred', marker='o', markersize=1)\n",
    "plt.plot(Y_test, label='Y', marker='s', markersize=1)\n",
    "# Adding labels and title\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Train Loss Curve')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "    plt.plot(X_train_1[:, 0, i], marker='o', markersize=1)\n",
    "    plt.ylim(min(X_train_1[:, 0, i]), max(X_train_1[:, 0, i]))\n",
    "    plt.xlabel('X-axis Label')\n",
    "    plt.ylabel('Y-axis Label', )\n",
    "    plt.title(f'Bearing1-1 Feature {i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "# Plotting the line chart\n",
    "    plt.plot(X_train_2[:, 0, i], marker='o', markersize=1)\n",
    "    plt.ylim(min(X_train_2[:, 0, i]), max(X_train_2[:, 0, i]))\n",
    "    plt.xlabel('X-axis Label')\n",
    "    plt.ylabel('Y-axis Label', )\n",
    "    plt.title(f'Bearing1-2 Feature {i+1}')\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "# Plotting the line chart\n",
    "    plt.plot(X_train_3[:, 0, i], marker='o', markersize=1)\n",
    "    plt.ylim(min(X_train_3[:, 0, i]), max(X_train_3[:, 0, i]))\n",
    "    plt.xlabel('X-axis Label')\n",
    "    plt.ylabel('Y-axis Label', )\n",
    "    plt.title(f'Bearing1-4 Feature {i+1}')\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "# Plotting the line chart\n",
    "    plt.plot(X_test[:, 0, i], marker='o', markersize=1)\n",
    "    plt.ylim(min(X_test[:, 0, i]), max(X_test[:, 0, i]))\n",
    "    plt.xlabel('X-axis Label')\n",
    "    plt.ylabel('Y-axis Label', )\n",
    "    plt.title(f'Bearing1-3 Feature {i+1}')\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
