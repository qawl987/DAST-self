{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "sys.path.append('/home/kai/DAST/network')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from DAST_utils import *\n",
    "from DAST_Network import *\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DASTModel():\n",
    "    def __init__(self, train_datasets: List[str], test_dataset: List[str], data_path: str, is_norm: bool, hyper_parameters: dict, model_save_path: str, model_save_name: str) -> None:\n",
    "        self.TRAIN_DATASETS = train_datasets\n",
    "        self.TEST_DATASETS = test_dataset\n",
    "        self.DATA_PATH = data_path\n",
    "        self.MODEL_SAVE_PATH = model_save_path\n",
    "        self.MODEL_SAVE_NAME = model_save_name\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.Y_train = []\n",
    "        self.Y_test = []\n",
    "        self.HP = hyper_parameters\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.best_predict = []\n",
    "        self.last_predict_y = None\n",
    "        self.train_loss_list = []\n",
    "        self.test_loss_list = []\n",
    "        self.best_mse_loss = 10000.0\n",
    "        self.best_rmse_loss = None\n",
    "        self.best_train_loss = 10000.0\n",
    "        self.norm = '_norm' if is_norm else ''\n",
    "        self.best_model_params = None\n",
    "        \n",
    "    @staticmethod\n",
    "    def RMSE(target, pred):\n",
    "        square_error = (target - pred) ** 2\n",
    "        mse =  (torch.sum(square_error)) / len(target)\n",
    "        rmse = mse ** 0.5\n",
    "        return rmse\n",
    "    \n",
    "    @staticmethod\n",
    "    def MAE(target, pred):\n",
    "        absolute_error = np.abs(target - pred)\n",
    "        return torch.sum(absolute_error) / len(target)\n",
    "    \n",
    "    def _load_x_y(self, folder: str):\n",
    "        y_tmp = np.load(f'{self.DATA_PATH}/{folder}/{folder}_Y.npy')\n",
    "        feature1 = np.load(f'{self.DATA_PATH}/{folder}/{folder}_X{self.norm}_2560.npy')\n",
    "        feature2 = np.load(f'{self.DATA_PATH}/{folder}/{folder}_X{self.norm}_1280.npy')\n",
    "        feature3 = np.load(f'{self.DATA_PATH}/{folder}/{folder}_X{self.norm}_640.npy')\n",
    "        X_train = np.concatenate((feature1, feature2, feature3), axis=2)\n",
    "        return X_train, np.reshape(y_tmp, ((len(y_tmp), -1)))\n",
    "    \n",
    "    def _concate(self):\n",
    "        self.X_train = np.concatenate(self.X_train, axis=0)\n",
    "        self.Y_train = np.concatenate(self.Y_train, axis=0)\n",
    "        self.X_test = np.concatenate(self.X_test, axis=0)\n",
    "        self.Y_test = np.concatenate(self.Y_test, axis=0)\n",
    "\n",
    "    def _load_np(self,):\n",
    "        # train\n",
    "        for folder in self.TRAIN_DATASETS:\n",
    "            X_train, Y_train = self._load_x_y(folder)\n",
    "            self.X_train.append(X_train)\n",
    "            self.Y_train.append(Y_train)\n",
    "        # test\n",
    "        for folder in self.TEST_DATASETS:\n",
    "            X_test, Y_test = self._load_x_y(folder)\n",
    "            self.X_test.append(X_test)\n",
    "            self.Y_test.append(Y_test)\n",
    "        \n",
    "    def _loop_feature(self, X, selected_indices):\n",
    "        extracted_values_list = []\n",
    "        for i in range(7):\n",
    "            for num in selected_indices:\n",
    "                extracted_values = X[:, :, num + 16 * i]\n",
    "                extracted_values_list.append(extracted_values)\n",
    "        result_array = np.stack(extracted_values_list, axis=-1)\n",
    "        return result_array\n",
    "    \n",
    "    def _select_feature(self, selected_indices):\n",
    "        for i in range(len(self.X_train)):\n",
    "            self.X_train[i] = self._loop_feature(self.X_train[i], selected_indices)\n",
    "        for i in range(len(self.X_test)):\n",
    "            self.X_test[i] = self._loop_feature(self.X_test[i], selected_indices)\n",
    "        \n",
    "    def _tensorizing(self):\n",
    "        self.X_train = Variable(torch.Tensor(self.X_train).float())\n",
    "        self.Y_train = Variable(torch.Tensor(self.Y_train).float())\n",
    "        self.X_test = Variable(torch.Tensor(self.X_test).float())\n",
    "        self.Y_test = Variable(torch.Tensor(self.Y_test).float())\n",
    "        \n",
    "    def _get_dataloader(self):\n",
    "        train_dataset = TensorDataset(self.X_train, self.Y_train)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=self.HP['batch_size'], shuffle=False)\n",
    "        test_dataset = TensorDataset(self.X_test, self.Y_test)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=self.HP['batch_size'], shuffle=False)\n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def _get_model(self):\n",
    "        model = DAST(self.HP['dim_val_s'], self.HP['dim_attn_s'], self.HP['dim_val_t'], self.HP['dim_attn_t'], self.HP['dim_val'], self.HP['dim_attn'], self.HP['time_step'], self.HP['feature_len'], self.HP['dec_seq_len'], self.HP['output_sequence_length'], self.HP['n_decoder_layers'], self.HP['n_encoder_layers'], self.HP['n_heads'], self.HP['debug'])\n",
    "        model = model.to(self.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.HP['lr'])\n",
    "        criterion = nn.MSELoss()\n",
    "        return model, optimizer, criterion\n",
    "\n",
    "    def train(self, model: DAST, optimizer: torch.optim.Optimizer, criterion, train_loader: DataLoader, epoch: int):\n",
    "        model.train()\n",
    "        tmp_loss_list = []\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for _, (X, Y) in enumerate(loop):\n",
    "            batch_X = X.to(self.device)\n",
    "            batch_Y = Y.to(self.device)\n",
    "            out = model(batch_X)\n",
    "            loss = criterion(out, batch_Y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tmp_loss_list.append(loss.item())\n",
    "        loss_eopch = np.mean(np.array(tmp_loss_list))\n",
    "        self.train_loss_list.append(loss_eopch)\n",
    "        if (loss_eopch.item() < self.best_train_loss):\n",
    "            self.best_train_loss = loss_eopch.item()\n",
    "        print('epoch = ',epoch,\n",
    "                'train_loss = ',loss_eopch.item())\n",
    "\n",
    "    def eval(self, model: DAST, test_loader: DataLoader, criterion, epoch: int):\n",
    "        model.eval()\n",
    "        prediction_list = []\n",
    "        with torch.no_grad():\n",
    "            for _ ,(batch_x, _) in enumerate(test_loader):\n",
    "                batch_X = batch_x.to(self.device)\n",
    "                prediction = model(batch_X)\n",
    "                prediction_list.append(prediction)\n",
    "\n",
    "        out_batch_pre = torch.cat(prediction_list).detach().cpu()\n",
    "        rmse_loss = self.RMSE(self.Y_test, out_batch_pre, )\n",
    "        mae_loss = self.MAE(self.Y_test, out_batch_pre, )\n",
    "        test_loss = criterion(out_batch_pre, self.Y_test)\n",
    "        self.test_loss_list.append(test_loss)\n",
    "        if (test_loss.item() < self.best_mse_loss):\n",
    "            self.best_mse_loss = test_loss.item()\n",
    "            self.best_rmse_loss = rmse_loss.item()\n",
    "            self.best_predict = np.reshape(out_batch_pre, (-1)).tolist()\n",
    "            torch.save(model.state_dict(), f'{self.MODEL_SAVE_PATH}/{self.MODEL_SAVE_NAME}.pt')\n",
    "        print('rmse_loss = ', rmse_loss.item(),\n",
    "                'mae_loss = ', mae_loss.item(),\n",
    "                'mse_loss = ', test_loss.item())\n",
    "        if epoch == self.HP['epochs'] - 1:\n",
    "            self.last_predict_y = out_batch_pre\n",
    "\n",
    "    def main(self, selected_indices):\n",
    "        self._load_np()\n",
    "        self._select_feature(selected_indices)\n",
    "        self._concate()\n",
    "        self._tensorizing()\n",
    "        model, optimizer, criterion = self._get_model()\n",
    "        train_loader, test_loader = self._get_dataloader()\n",
    "        times = 0\n",
    "        for epoch in range(self.HP['epochs']):\n",
    "            start = time.time()\n",
    "            self.train(model, optimizer, criterion, train_loader, epoch)\n",
    "            end = time.time()\n",
    "            times += end - start\n",
    "            self.eval(model, test_loader, criterion, epoch)\n",
    "        print(f\"train time: {times/100:.7f}, s/epoch\")\n",
    "        print(f\"embed1: {self.HP['dim_val_s']}, embed2: {self.HP['dim_attn_s']}, lr: {self.HP['lr']}, dec_seq_len: {self.HP['dec_seq_len']}\")\n",
    "        print(f\"{self.best_train_loss:.7f}\")\n",
    "        print(f\"{self.best_mse_loss:.7f}\")\n",
    "        print(f\"{self.best_rmse_loss:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../../data/10FEMTO/processed_data/'\n",
    "TRAIN_DATASETS = ['Bearing1_1', 'Bearing1_2']\n",
    "TEST_DATASET = ['Bearing1_3', 'Bearing1_4', 'Bearing1_5', 'Bearing1_6', 'Bearing1_7']\n",
    "# TRAIN_DATASETS = ['Bearing2_1', 'Bearing2_2']\n",
    "# TEST_DATASET = ['Bearing2_3', 'Bearing2_4', 'Bearing2_5', 'Bearing2_6', 'Bearing2_7']\n",
    "# TRAIN_DATASETS = ['Bearing3_1', 'Bearing3_2']\n",
    "# TEST_DATASET = ['Bearing3_3']\n",
    "\n",
    "MODEL_SAVE_NAME = 'Bearing3_pretrain_7'\n",
    "IS_NORM = False\n",
    "MODEL_SAVE_PATH = '../../../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = [1, 3, 5, 7, 9, 10, 14]\n",
    "# selected_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "FEATURE_LEN = len(selected_indices)\n",
    "FEATURE_SIZE = 20\n",
    "EMBEDD = 20\n",
    "HYPER_PARAMETERS = {\n",
    "    'batch_size': 256,\n",
    "    'dim_val': FEATURE_SIZE,\n",
    "    'dim_attn': EMBEDD,\n",
    "    'dim_val_t': FEATURE_SIZE,\n",
    "    'dim_attn_t': EMBEDD,\n",
    "    'dim_val_s': FEATURE_SIZE,\n",
    "    'dim_attn_s': EMBEDD,\n",
    "    'n_heads': 4,\n",
    "    'n_decoder_layers': 1,\n",
    "    'n_encoder_layers': 2,\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 100,\n",
    "    'time_step': 40,\n",
    "    # limit how many last input used, important!\n",
    "    'dec_seq_len': 6,\n",
    "    'output_sequence_length': 1,\n",
    "    'feature_len': FEATURE_LEN,\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dast_model = DASTModel(train_datasets=TRAIN_DATASETS, test_dataset=TEST_DATASET, data_path=DATA_PATH, is_norm=IS_NORM, hyper_parameters=HYPER_PARAMETERS, model_save_path=MODEL_SAVE_PATH, model_save_name=MODEL_SAVE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dast_model.main(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dast_model.Y_test.detach().cpu().numpy()\n",
    "y = np.reshape(y, -1)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_list():\n",
    "    plt.plot(dast_model.train_loss_list, label='Train loss', marker='o', markersize=1)\n",
    "    plt.plot(dast_model.test_loss_list, label='Test loss', marker='s', markersize=1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "loss_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_predict():\n",
    "    plt.plot(dast_model.best_predict, label='Pred', marker='o', markersize=1)\n",
    "    plt.plot(y, label='Y', marker='s', markersize=1)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('RUL')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "best_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_predict_vs_y():\n",
    "    last_predict_y = np.reshape(dast_model.last_predict_y, (-1))\n",
    "    last_predict_y = last_predict_y.tolist()\n",
    "    plt.plot(last_predict_y, label='Pred', marker='o', markersize=1)\n",
    "    plt.plot(y, label='Y', marker='s', markersize=1)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('RUL')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "last_predict_vs_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{dast_model.best_train_loss:.7f}\")\n",
    "print(f\"{dast_model.best_mse_loss:.7f}\")\n",
    "print(f\"{dast_model.best_rmse_loss:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
