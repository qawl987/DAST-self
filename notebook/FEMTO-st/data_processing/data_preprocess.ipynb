{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft\n",
    "import os\n",
    "from scipy.optimize import fsolve\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEMTO = '../../../data/10FEMTO/raw_data/Validation_set/'\n",
    "POST_PROCESS = '../../../data/10FEMTO/processed_data/'\n",
    "# DATASET = [('Bearing1_1', True, 100), ('Bearing1_2', True, 10), ('Bearing1_3', False, 100), ('Bearing1_4', True, 40)]\n",
    "DATASET = [('Bearing1_3', False, 100)]\n",
    "# DATASET = [('Bearing1_1', True, 100)]\n",
    "# DATASET = [('Bearing1_3', False), ('Bearing1_4', True), ('Bearing1_5', True), ('Bearing1_6', True), ('Bearing1_7', True), ('Bearing2_3', False), ('Bearing3_1', False)]\n",
    "WINDOW_SIZE = 40\n",
    "MIN_SIGNAL_SIZE = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process():\n",
    "    def __init__(self, folders: [(str, bool, int)], window_size: int, min_signal: int) -> None:\n",
    "        self.folders = folders\n",
    "        self.life = None\n",
    "        self.Y = []\n",
    "        self.train = None\n",
    "        self.window_size = window_size\n",
    "        self.min_signal = min_signal\n",
    "        \n",
    "    def _equation(self, tau, a, convergence):\n",
    "        return 1 + np.exp(a) - np.exp((convergence * tau) + a)\n",
    "    \n",
    "    def HI(self, t, a , tau):\n",
    "        return 1 + np.exp(a) - np.exp((t * tau) + a)\n",
    "    \n",
    "    def loop_folder(self):\n",
    "        for (folder, is_train, convergence) in self.folders:\n",
    "            self.Y = []\n",
    "            feature1s = []\n",
    "            feature2s = []\n",
    "            feature3s = []\n",
    "            print(folder, is_train)\n",
    "            try:\n",
    "                self.train = is_train\n",
    "                accs = os.listdir(FEMTO+folder)\n",
    "                accs.sort()\n",
    "                accs = [acc for acc in accs if acc.startswith('acc')]\n",
    "                self.life = len(accs)\n",
    "                for stamp, acc in enumerate(accs):\n",
    "                    feature1, feature2, feature3 = self._get_feature(f'{FEMTO}/{folder}_norm/{acc}')\n",
    "                    feature1s.append(feature1)\n",
    "                    feature2s.append(feature2)\n",
    "                    feature3s.append(feature3)\n",
    "                \n",
    "                feature1s = self._slide_x_window(feature1s)\n",
    "                feature2s = self._slide_x_window(feature2s)\n",
    "                feature3s = self._slide_x_window(feature3s)\n",
    "                self._save_x_data(folder, feature1s, '2560')\n",
    "                self._save_x_data(folder, feature2s, '1280')\n",
    "                self._save_x_data(folder, feature3s, '640')\n",
    "                # y_HI = self._reconstruct_HI(convergence)\n",
    "                # self.Y = self._slide_y_window(y_HI)\n",
    "                # self._save_y_data(folder)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(folder)\n",
    "                \n",
    "    def _save_x_data(self, folder: str, features, signal_size: int):\n",
    "        np.save(f'{POST_PROCESS}{folder}/{folder}_train_X_norm_{signal_size}', features) if self.train else np.save(f'{POST_PROCESS}{folder}/{folder}_test_X_norm_{signal_size}', features)\n",
    "\n",
    "    def _save_y_data(self, folder):\n",
    "        np.save(f'{POST_PROCESS}{folder}/{folder}_train_Y', self.Y) if self.train else np.save(f'{POST_PROCESS}{folder}/{folder}_test_Y', self.Y)\n",
    "    \n",
    "    def _reconstruct_HI(self, convergence: int):\n",
    "        initial_guess = 0\n",
    "        a = 1\n",
    "        result = fsolve(self._equation, initial_guess, args=(a, convergence))\n",
    "        tau = result[0]\n",
    "        print(f\"The solution for τ is: {tau}\")\n",
    "        partial_HI = partial(self.HI, a=a, tau=tau)\n",
    "        rul = [i for i in range(self.life)]\n",
    "        hi_y = list(map(partial_HI, rul))\n",
    "        min_value = min(hi_y)\n",
    "        max_value = max(hi_y)\n",
    "        normalized_values = [(x - min_value) / (max_value - min_value) for x in hi_y]\n",
    "        return normalized_values\n",
    "\n",
    "    def _get_feature(self, acc: str):\n",
    "        x = pd.read_csv(acc, header=None, sep=',')\n",
    "        feature1 = self._extract_feature(x, self.min_signal * 4)\n",
    "        tmp1 = self._extract_feature(x[:2 * self.min_signal], self.min_signal * 2)\n",
    "        tmp2 = self._extract_feature(x[2 * self.min_signal:], self.min_signal * 2)\n",
    "        feature2 = tmp1 + tmp2\n",
    "        tmp1 = self._extract_feature(x[:self.min_signal], self.min_signal)\n",
    "        tmp2 = self._extract_feature(x[self.min_signal:2 * self.min_signal], self.min_signal)\n",
    "        tmp3 = self._extract_feature(x[2 * self.min_signal:3 * self.min_signal], self.min_signal)\n",
    "        tmp4 = self._extract_feature(x[3 * self.min_signal:4 * self.min_signal], self.min_signal)\n",
    "        feature3 = tmp1 + tmp2 + tmp3 + tmp4\n",
    "        return feature1, feature2, feature3\n",
    "    \n",
    "    def _extract_feature(self, x: pd.DataFrame, LEN):\n",
    "        # time zone\n",
    "        x_abs = x.abs()\n",
    "        x_avg = x.sum() / LEN\n",
    "        mean_square_sum = ((x.apply(lambda x: x - x_avg)) ** 2).sum()\n",
    "        p1 = x.max()\n",
    "        p2 = x.min()\n",
    "        p3 = x_abs.max()\n",
    "        p4 = p1 - p2\n",
    "        p5 = x_abs.sum() / LEN\n",
    "        p6 = (x_abs.sum() ** 0.5 / LEN) * 2\n",
    "        p7 = mean_square_sum / (LEN -1)\n",
    "        p8 = (mean_square_sum / LEN) ** 0.5\n",
    "        p9 = ((x ** 2).sum() / LEN) ** 0.5\n",
    "        # p10 = ((x.apply(lambda x: x - x_avg)) ** 4).sum() / ((LEN - 1) * ((mean_square_sum / LEN)  ** 2))\n",
    "        p11 = (LEN * p9) / x_abs.sum()\n",
    "        p12 = p9 / p5\n",
    "        p13 = p3 / p9\n",
    "        p14 = p3 / p5\n",
    "        p15 = p3 / p6\n",
    "        p16 = p3 / (p9 ** 2)\n",
    "        \n",
    "        # frequency zone\n",
    "        fft_result = np.fft.fft(x.to_numpy(), axis=0)\n",
    "        N = len(fft_result)\n",
    "        amplitudes = np.abs(fft_result)\n",
    "        p17 = np.sum(amplitudes) / N\n",
    "        return [p1.iloc[0], p2.iloc[0], p3.iloc[0], p4.iloc[0], p5.iloc[0], p6.iloc[0], \n",
    "                p7.iloc[0], p8.iloc[0], p9.iloc[0], p11.iloc[0], p12.iloc[0], \n",
    "                p13.iloc[0], p14.iloc[0], p15.iloc[0], p16.iloc[0], p17]\n",
    "    \n",
    "    def _slide_y_window(self, y_hi):\n",
    "        y_windows = []\n",
    "        for i in range(self.life - self.window_size):\n",
    "            y_window = np.array(y_hi)[i + 40]\n",
    "            y_windows.append(y_window)\n",
    "        return np.array(y_windows)\n",
    "\n",
    "    def _slide_x_window(self, features):\n",
    "        feature_windows = []\n",
    "        for i in range(self.life - self.window_size):\n",
    "            feature_window = np.array(features)[i:i + self.window_size, :]\n",
    "            feature_windows.append(feature_window)\n",
    "        return np.array(feature_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearing1_3 False\n"
     ]
    }
   ],
   "source": [
    "process = Process(DATASET, WINDOW_SIZE, MIN_SIGNAL_SIZE)\n",
    "process.loop_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.load('/home/kai/DAST/data/10FEMTO/processed_data/Bearing1_2/Bearing1_2_train_X_2560.npy')\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = 2560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('../../../data/10FEMTO/raw_data/Validation_set/Bearing1_1_norm/acc_00001.csv', header=None, sep=',')\n",
    "# time zone\n",
    "x_abs = x.abs()\n",
    "x_avg = x.sum() / LEN\n",
    "mean_square_mean = ((x.apply(lambda x: x - x_avg)) ** 2).sum()\n",
    "p1 = x.min()\n",
    "p2 = x.max()\n",
    "p3 = x_abs.max()\n",
    "p4 = p2 - p1\n",
    "p5 = x_abs.sum() / LEN\n",
    "p6 = (x_abs.sum() ** 0.5 / LEN) * 2\n",
    "p7 = mean_square_mean / (LEN -1)\n",
    "p8 = (mean_square_mean / LEN) ** 0.5\n",
    "p9 = ((x ** 2).sum() / LEN) ** 0.5\n",
    "p10 = ((x.apply(lambda x: x - x_avg)) ** 3).sum() / ((LEN - 1) * (p8 ** 3))\n",
    "p11 = (LEN * p9) / x_abs.sum()\n",
    "p12 = p9 / p5\n",
    "p13 = p3 / p9\n",
    "p14 = p3 / p5\n",
    "p15 = p3 / p6\n",
    "p16 = p3 / (p9 ** 2)\n",
    "# frequency zone\n",
    "fft_result = np.fft.fft(x.to_numpy())\n",
    "N = len(fft_result)\n",
    "frequencies = np.fft.fftfreq(N, d=1)  # 采样频率为 2560 Hz\n",
    "amplitudes = np.abs(fft_result)\n",
    "p17 = np.sum(amplitudes) / N\n",
    "p18 = np.sum(frequencies * amplitudes) / np.sum(amplitudes)\n",
    "p19 = (np.sum(frequencies ** 2 * amplitudes) / np.sum(amplitudes)) ** 0.5\n",
    "p20 = ((np.sum((frequencies - p18) ** 2 * amplitudes)) / np.sum(amplitudes)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.763\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
